{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sdajYxSFDS-M"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import random\n",
    "import time\n",
    "import tensorflow as tf\n",
    "import datetime\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "import tempfile\n",
    "os.environ['KERAS_BACKEND'] = 'tensorflow'\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' # 3 = INFO, WARNING, and ERROR messages are not printed\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import FileLink\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import seaborn as sns \n",
    "%matplotlib inline\n",
    "from IPython.display import display, Image\n",
    "import matplotlib.image as mpimg\n",
    "import cv2\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_files       \n",
    "from keras.utils import np_utils\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "#from keras.models import Sequential, Model,save_model\n",
    "#from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization, GlobalAveragePooling2D\n",
    "#from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing import image\n",
    "#from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ModelCheckpoint,EarlyStopping\n",
    "\n",
    "from tensorflow.keras.models import Sequential, save_model,Model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization, GlobalAveragePooling2D\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GjY5b3G1IfNT"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 17943 images belonging to 10 classes.\n",
      "Found 4481 images belonging to 10 classes.\n",
      "Found 35910 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "IMAGE_SIZE = 224\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255,\n",
    "    height_shift_range=0.5,\n",
    "    width_shift_range = 0.5,\n",
    "    zoom_range = 0.5,\n",
    "    rotation_range=30,\n",
    "    validation_split=0.2)\n",
    "test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rescale=1./255)\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    '/Bangkit/imgs/train',\n",
    "    target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=\"categorical\",\n",
    "    subset='training',\n",
    "    shuffle=True)\n",
    "\n",
    "\n",
    "val_generator = train_datagen.flow_from_directory(\n",
    "   '/Bangkit/imgs/train',\n",
    "    target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "    batch_size=BATCH_SIZE, \n",
    "    class_mode=\"categorical\",\n",
    "    subset='validation',\n",
    "    shuffle=True)\n",
    "\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "   '/Bangkit/imgs/test',\n",
    "    target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "    batch_size=BATCH_SIZE, \n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 252
    },
    "colab_type": "code",
    "id": "eGG951B2LzFQ",
    "outputId": "b809ea82-4536-4889-efbf-fd01207c2447"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((32, 224, 224, 3), (32, 10))"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for image_batch, label_batch in train_generator:\n",
    "  break\n",
    "image_batch.shape, label_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7oEA1JhfM8iP"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Doing Hair or Makeup': 0, 'Drinking': 1, 'Operating Radio': 2, 'Reaching Behind': 3, 'Save Driving': 4, 'Talking On The Phone left': 5, 'Talking On The phone Right': 6, 'Talking to passenger': 7, 'Texting Left': 8, 'Texting Right': 9}\n"
     ]
    }
   ],
   "source": [
    "print (train_generator.class_indices)\n",
    "\n",
    "labels = '\\n'.join(sorted(train_generator.class_indices.keys()))\n",
    "\n",
    "with open('labels.txt', 'w') as f:\n",
    "  f.write(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gpwsLq20VWVS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_9 (Conv2D)            (None, 222, 222, 512)     14336     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 111, 111, 512)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 109, 109, 256)     1179904   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 54, 54, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 52, 52, 128)       295040    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 26, 26, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 24, 24, 64)        73792     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 9216)              0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 512)               4719104   \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 6,287,306\n",
      "Trainable params: 6,287,306\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1 = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(512, (3, 3), activation='relu', input_shape=(224, 224, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Conv2D(256, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])\n",
    "\n",
    "checkpointer = ModelCheckpoint('cnn_stratch_best.hdf5', verbose=1, save_best_only=True)\n",
    "earlystop = EarlyStopping(monitor='val_accuracy', patience=2, verbose=1)\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.0001) \n",
    "model1.compile(optimizer=opt,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "EUX88aljV6-K",
    "outputId": "a54ef8ca-2ad0-4193-c3c3-cf11a3306e7c",
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-53-0d357e1e644b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0mmodel1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mep\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcheckpointer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mearlystop\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'x_train' is not defined"
     ]
    }
   ],
   "source": [
    "history =model1.fit(x_train, y_train, validation_data=(x_test, y_test),epochs=ep,batch_size=bs, callbacks=[checkpointer,earlystop,cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KUyYHABTZ_65"
   },
   "outputs": [],
   "source": [
    "def plot_train_history(history):\n",
    "    # Summarize history for accuracy\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.title('Model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "    # Summarize history for loss\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('Model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 573
    },
    "colab_type": "code",
    "id": "Iv_QUr7dnunv",
    "outputId": "17307856-84cf-4a52-f6e3-078fb446af0d"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-a4e1d345ded1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplot_train_history\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "plot_train_history(history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 337
    },
    "colab_type": "code",
    "id": "kVLBBJOcOGXB",
    "outputId": "97f2d40d-d07d-443a-acbf-efc9e1dd04d7"
   },
   "outputs": [],
   "source": [
    "#evaluasi model\n",
    "train_acc = model1.evaluate(x_train, y_train)\n",
    "test_acc = model1.evaluate(x_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yEHok6TcTCsn"
   },
   "outputs": [],
   "source": [
    "IMG_SHAPE = (IMAGE_SIZE, IMAGE_SIZE, 3)\n",
    "\n",
    "mobnet = tf.keras.applications.MobileNet(input_shape=IMG_SHAPE,\n",
    "                                        include_top=False, \n",
    "                                         weights='imagenet')\n",
    "mobnet.trainable=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = tf.keras.Sequential([\n",
    "  mobnet,\n",
    "  tf.keras.layers.Conv2D(1024, 3, activation='relu'),\n",
    "  #tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.GlobalAveragePooling2D(),\n",
    "  tf.keras.layers.Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "mobilenet_1.00_224 (Model)   (None, 7, 7, 1024)        3228864   \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 5, 5, 1024)        9438208   \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_7 ( (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 10)                10250     \n",
      "=================================================================\n",
      "Total params: 12,677,322\n",
      "Trainable params: 9,448,458\n",
      "Non-trainable params: 3,228,864\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "checkpointer = ModelCheckpoint('mobnet_best.hdf5', verbose=1, save_best_only=True)\n",
    "earlystop = EarlyStopping(monitor='val_acc', patience=10, verbose=1)\n",
    "model2.compile(optimizer=tf.keras.optimizers.Adam(), \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 561 steps, validate for 141 steps\n",
      "Epoch 1/10\n",
      "560/561 [============================>.] - ETA: 0s - loss: 2.4680 - accuracy: 0.2285\n",
      "Epoch 00001: val_loss improved from inf to 1.94189, saving model to mobnet_best.hdf5\n",
      "561/561 [==============================] - 669s 1s/step - loss: 2.4666 - accuracy: 0.2289 - val_loss: 1.9419 - val_accuracy: 0.2988\n",
      "Epoch 2/10\n",
      "560/561 [============================>.] - ETA: 0s - loss: 1.6342 - accuracy: 0.4085\n",
      "Epoch 00002: val_loss improved from 1.94189 to 1.86381, saving model to mobnet_best.hdf5\n",
      "561/561 [==============================] - 618s 1s/step - loss: 1.6339 - accuracy: 0.4087 - val_loss: 1.8638 - val_accuracy: 0.3464\n",
      "Epoch 3/10\n",
      "560/561 [============================>.] - ETA: 0s - loss: 1.4706 - accuracy: 0.4798\n",
      "Epoch 00003: val_loss improved from 1.86381 to 1.72601, saving model to mobnet_best.hdf5\n",
      "561/561 [==============================] - 550s 981ms/step - loss: 1.4702 - accuracy: 0.4801 - val_loss: 1.7260 - val_accuracy: 0.3937\n",
      "Epoch 4/10\n",
      "560/561 [============================>.] - ETA: 0s - loss: 1.3686 - accuracy: 0.5138\n",
      "Epoch 00004: val_loss improved from 1.72601 to 1.62617, saving model to mobnet_best.hdf5\n",
      "561/561 [==============================] - 453s 808ms/step - loss: 1.3683 - accuracy: 0.5139 - val_loss: 1.6262 - val_accuracy: 0.4245\n",
      "Epoch 5/10\n",
      "560/561 [============================>.] - ETA: 0s - loss: 1.3161 - accuracy: 0.5334\n",
      "Epoch 00005: val_loss did not improve from 1.62617\n",
      "561/561 [==============================] - 469s 836ms/step - loss: 1.3158 - accuracy: 0.5335 - val_loss: 1.6969 - val_accuracy: 0.4059\n",
      "Epoch 6/10\n",
      "560/561 [============================>.] - ETA: 0s - loss: 1.2622 - accuracy: 0.5551\n",
      "Epoch 00006: val_loss did not improve from 1.62617\n",
      "561/561 [==============================] - 468s 835ms/step - loss: 1.2623 - accuracy: 0.5551 - val_loss: 1.8845 - val_accuracy: 0.3763\n",
      "Epoch 7/10\n",
      "560/561 [============================>.] - ETA: 0s - loss: 1.2205 - accuracy: 0.5708\n",
      "Epoch 00007: val_loss did not improve from 1.62617\n",
      "561/561 [==============================] - 467s 833ms/step - loss: 1.2212 - accuracy: 0.5706 - val_loss: 1.7185 - val_accuracy: 0.4122\n",
      "Epoch 8/10\n",
      "560/561 [============================>.] - ETA: 0s - loss: 1.1846 - accuracy: 0.5798\n",
      "Epoch 00008: val_loss did not improve from 1.62617\n",
      "561/561 [==============================] - 458s 817ms/step - loss: 1.1846 - accuracy: 0.5798 - val_loss: 1.7439 - val_accuracy: 0.4182\n",
      "Epoch 9/10\n",
      "560/561 [============================>.] - ETA: 0s - loss: 1.1536 - accuracy: 0.5990\n",
      "Epoch 00009: val_loss did not improve from 1.62617\n",
      "561/561 [==============================] - 454s 809ms/step - loss: 1.1537 - accuracy: 0.5988 - val_loss: 1.7491 - val_accuracy: 0.4193\n",
      "Epoch 10/10\n",
      "560/561 [============================>.] - ETA: 0s - loss: 1.1368 - accuracy: 0.6058\n",
      "Epoch 00010: val_loss did not improve from 1.62617\n",
      "561/561 [==============================] - 453s 808ms/step - loss: 1.1367 - accuracy: 0.6056 - val_loss: 1.9828 - val_accuracy: 0.3787\n"
     ]
    }
   ],
   "source": [
    "history = model2.fit(train_generator, \n",
    "                    steps_per_epoch=len(train_generator), \n",
    "                    epochs=10, \n",
    "                    validation_data=val_generator, \n",
    "                    validation_steps=len(val_generator),callbacks=[checkpointer,earlystop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50589164"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=tf.keras.models.load_model(\"./mobnet_best.hdf5\")\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.experimental_new_converter = True\n",
    "tflite_model = converter.convert()\n",
    "open(\"converted_model.tflite\", \"wb\").write(tflite_model)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_DIR = tempfile.gettempdir()\n",
    "version = 1\n",
    "export_path = os.path.join(MODEL_DIR, str(version))\n",
    "print('export_path = {}\\n'.format(export_path))\n",
    "\n",
    "tf.keras.models.save_model(\n",
    "    model1,\n",
    "    export_path,\n",
    "    overwrite=True,\n",
    "    include_optimizer=True,\n",
    "    save_format=None,\n",
    "    signatures=None,\n",
    "    options=None\n",
    ")\n",
    "\n",
    "print('\\nSaved model:')\n",
    "!ls -l {export_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "mobnet.trainable=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of layers in the base model:  87\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of layers in the base model: \", len(mobnet.layers))\n",
    "\n",
    "# Fine tune from this layer onwards\n",
    "fine_tune_at = 70\n",
    "\n",
    "# Freeze all the layers before the `fine_tune_at` layer\n",
    "for layer in mobnet.layers[:fine_tune_at]:\n",
    "    layer.trainable =  False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "  mobnet,\n",
    "  tf.keras.layers.Conv2D(1024, 3, activation='relu'),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.GlobalAveragePooling2D(),\n",
    "  tf.keras.layers.Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "mobilenet_1.00_224 (Model)   (None, 7, 7, 1024)        3228864   \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 5, 5, 1024)        9438208   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 5, 5, 1024)        0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_8 ( (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 10)                10250     \n",
      "=================================================================\n",
      "Total params: 12,677,322\n",
      "Trainable params: 11,305,482\n",
      "Non-trainable params: 1,371,840\n",
      "_________________________________________________________________\n",
      "Number of trainable variables = 19\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n",
    "print('Number of trainable variables = {}'.format(len(model.trainable_variables)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer = tf.keras.optimizers.Adam(1e-5),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 561 steps, validate for 141 steps\n",
      "Epoch 1/20\n",
      "257/561 [============>.................] - ETA: 4:11 - loss: 2.2131 - accuracy: 0.2095"
     ]
    }
   ],
   "source": [
    "history_fine = model.fit(train_generator, \n",
    "                         steps_per_epoch=len(train_generator), \n",
    "                         epochs=20, \n",
    "                         validation_data=val_generator, \n",
    "                         validation_steps=len(val_generator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Bangkit.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
